from pydantic import BaseModel, Field, ConfigDict, field_validator
from typing import Dict, Optional
from collections import defaultdict
from pydantic_ai.usage import Usage # Import the base Usage class


class SearchTask(BaseModel):
    """Represents a single search task generated by the Planner LLM."""
    model_config = ConfigDict(extra='ignore')
    query: str = Field(..., description="The search query string to execute.", min_length=1)
    endpoint: str = Field("/search", description="The Serper API endpoint to target (e.g., /search, /scholar).")
    num_results: int = Field(5, description="Desired number of search results.", ge=1, le=20)
    reasoning: Optional[str] = Field(None, description="Planner's reasoning for generating this specific search task.")

    @field_validator('endpoint')
    def validate_endpoint(cls, v: str) -> str:
        allowed_endpoints = ['/search', '/scholar', '/news']
        if v not in allowed_endpoints:
            raise ValueError(f"Invalid endpoint '{v}'. Allowed: {allowed_endpoints}")
        return v

class TokenUsageCounter(BaseModel):
    """Stores token counts for a specific LLM role or the total."""
    model_config = ConfigDict(frozen=True) # Make immutable

    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0

class UsageStatistics(BaseModel):
    """Detailed statistics about resource usage, potentially used by multiple agencies."""
    model_config = ConfigDict(frozen=True) # Make immutable

    token_usage: Optional[Dict[str, TokenUsageCounter]] = Field(None, description="Token counts broken down by LLM role or task.")
    estimated_cost: Optional[Dict[str, float]] = Field(None, description="Estimated costs broken down by LLM role or task (USD)." )
    serper_queries_used: int = Field(..., description="Total number of calls made to the Serper Search API.")
    sources_processed_count: int = Field(..., description="Total number of unique source URLs fetched and processed.")
    refinement_iterations_run: int = Field(..., description="Number of refinement loops (search -> process -> refine) executed.") 

# --- NEW RunUsage Class ---
class RunUsage:
    """Tracks detailed usage across an orchestration run."""
    _agent_usage: Dict[str, Usage]
    _serper_queries: int
    _sources_processed: int
    _refinement_iterations: int

    def __init__(self):
        self._agent_usage = defaultdict(Usage)
        self._serper_queries = 0
        self._sources_processed = 0
        self._refinement_iterations = 0

    def update_agent_usage(self, agent_name: str, usage_increment: Usage):
        """Updates the usage count for a specific agent."""
        self._agent_usage[agent_name] += usage_increment

    def increment_serper_queries(self, count: int = 1):
        """Increments the count of Serper API calls."""
        self._serper_queries += count

    def increment_sources_processed(self, count: int = 1):
        """Increments the count of unique sources processed."""
        self._sources_processed += count

    def increment_refinement_iterations(self, count: int = 1):
        """Increments the count of refinement iterations."""
        self._refinement_iterations += count

    def get_statistics(self) -> UsageStatistics:
        """Converts tracked usage into the UsageStatistics schema."""
        token_usage_map: Dict[str, TokenUsageCounter] = {}
        for agent_name, agent_usage in self._agent_usage.items():
            token_usage_map[agent_name] = TokenUsageCounter(
                prompt_tokens=agent_usage.request_tokens or 0,
                completion_tokens=agent_usage.response_tokens or 0,
                total_tokens=agent_usage.total_tokens or 0,
            )

        # TODO: Implement cost estimation if needed
        estimated_cost_map = None # Placeholder

        return UsageStatistics(
            token_usage=token_usage_map if token_usage_map else None,
            estimated_cost=estimated_cost_map,
            serper_queries_used=self._serper_queries,
            sources_processed_count=self._sources_processed,
            refinement_iterations_run=self._refinement_iterations,
        ) 