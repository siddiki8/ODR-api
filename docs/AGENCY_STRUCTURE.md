# Agency Structure & Quickstart Guide

This document provides a comprehensive overview of the "Agency" structure within the Open Deep Research API Framework. It serves as both documentation and a practical guide for developers looking to create new, specialized research agencies.

## 🏛️ What is an Agency?

In this framework, an **Agency** is a self-contained, modular component responsible for handling a specific type of research or reasoning task. Think of it as a specialized department within a larger organization. Each agency orchestrates a team of LLM-powered **Agents** and leverages shared **Services** to execute a complex workflow.

For example, the included `deep_research` agency is designed for in-depth, multi-step research, while a new agency might be created for `financial_analysis`, `code_review`, or `scientific_literature_synthesis`.

## anatomy of an Agency

An agency is represented by a directory inside `app/agencies/`. The `deep_research` agency serves as our reference implementation. A typical agency directory contains the following key files:

| File | Purpose | Reference Example |
| :--- | :--- | :--- |
| `orchestrator.py` | **The heart of the agency.** Defines the main workflow, sequencing calls to agents and services to fulfill the user's request. | `app/agencies/deep_research/orchestrator.py` |
| `agents.py` | **The workforce.** Implements the specialized LLM agents (e.g., Planner, Writer, Refiner). Each agent has a specific role and is responsible for a distinct reasoning step. | `app/agencies/deep_research/agents.py` |
| `schemas.py` | **The data contracts.** Defines the Pydantic models for the agency's data structures, including agent inputs/outputs and API request/response models. This ensures data consistency. | `app/agencies/deep_research/schemas.py` |
| `config.py` | **Agency-specific settings.** Contains Pydantic models for configuration parameters that are unique to this agency's workflow, such as LLM model names or behavior thresholds. | `app/agencies/deep_research/config.py` |
| `routes.py` | **The API endpoint.** Contains the FastAPI router that exposes the agency's functionality to the outside world, typically via a WebSocket endpoint. | `app/agencies/deep_research/routes.py` |
| `callbacks.py` | **Real-time communication.** Implements the handler for sending status updates back to the client (e.g., over a WebSocket), providing visibility into the ongoing process. | `app/agencies/deep_research/callbacks.py` |
| `helpers.py` | **Utility functions.** (Optional) Contains helper functions specific to the agency's workflow, often combining calls to shared services to simplify the orchestrator logic. | `app/agencies/deep_research/helpers.py` |
| `prompts.py`| **Prompt management.** (Optional) A dedicated place to store and manage the potentially large and complex prompts used by the agents. | Not present in `deep_research`, but a good practice. |

---

## 🚀 Quickstart: Creating a New Agency

Let's create a new, simplified agency called `quick_report`. This agency will take a topic, perform a single search, and write a brief report.

### Step 1: Create the Directory Structure

Create a new folder `app/agencies/quick_report`. Inside it, create the following empty files:

```
app/agencies/quick_report/
├── __init__.py
├── agents.py
├── callbacks.py
├── config.py
├── orchestrator.py
├── routes.py
└── schemas.py
```

### Step 2: Define Configuration (`config.py`)

Define the settings your agency will need. At a minimum, this usually includes LLM configurations.

```python
# app/agencies/quick_report/config.py
from __future__ import annotations
from pydantic_settings import BaseSettings
from app.core.schemas import LLMConfig

class QuickReportConfig(BaseSettings):
    """Configuration for the Quick Report Agency."""
    reporter_llm_config: LLMConfig = LLMConfig(model="gpt-4-turbo")
    # Add any other specific configs, e.g., search result count
    num_search_results: int = 5

    class Config:
        env_file = ".env"
        env_prefix = "QUICK_REPORT_"
        extra = "ignore"
```

### Step 3: Define Schemas (`schemas.py`)

Define the Pydantic models for your agent's output and the final API response.

```python
# app/agencies/quick_report/schemas.py
from __future__ import annotations
from pydantic import BaseModel, Field
from app.core.schemas import UsageStatistics

class Report(BaseModel):
    """The final report generated by the agent."""
    title: str = Field(..., description="The title of the report.")
    content: str = Field(..., description="The main content of the report, in Markdown format.")

class QuickReportResponse(BaseModel):
    """The final response object for the API."""
    report: Report
    usage_statistics: UsageStatistics
```

### Step 4: Create the Agent (`agents.py`)

Define the LLM agent(s). For this example, we only need one: a `Reporter` agent.

```python
# app/agencies/quick_report/agents.py
from __future__ import annotations
from pydantic_ai.llm import LLM
from pydantic_ai import pydantic_ai_processor
from . import schemas

# It's good practice to define prompt templates here or in a separate prompts.py
REPORTER_SYSTEM_PROMPT = "You are an expert researcher. Your task is to write a concise report based on the provided search results. The report should have a title and content."
REPORTER_USER_MESSAGE_TEMPLATE = """
Generate a report on the topic: '{user_query}'.

Use the following search results as your information source:
{search_results_json}
"""

@pydantic_ai_processor
def create_reporter_agent(llm: LLM) -> schemas.Report:
    """An agent that writes a report from search results."""
    pass

class AgencyAgents:
    """A collection of all agents used by the agency."""
    def __init__(self, reporter_llm: LLM):
        self.reporter = create_reporter_agent(reporter_llm)

    @classmethod
    def from_config(cls, config: "QuickReportConfig", llm_provider: "LLMProvider"):
        reporter_llm = llm_provider.get_llm(config.reporter_llm_config)
        return cls(reporter_llm=reporter_llm)

def format_search_results_for_prompt(results: list) -> str:
    """Formats search results into a string for the LLM prompt."""
    import json
    return json.dumps([res.model_dump() for res in results], indent=2)
```

### Step 5: Implement the Orchestrator (`orchestrator.py`)

This is where you define the workflow.

1.  **Call Search Service:** Get information.
2.  **Call Agent:** Process information and generate the report.
3.  **Return:** Package the results.

```python
# app/agencies/quick_report/orchestrator.py
from __future__ import annotations
import logging
from . import agents, schemas, config
from app.core.schemas import RunUsage
from app.services.search import execute_search_queries, SerperConfig, SearchTask

logger = logging.getLogger(__name__)

async def run_quick_report_orchestration(
    user_query: str,
    agents_collection: agents.AgencyAgents,
    agency_config: config.QuickReportConfig
) -> schemas.QuickReportResponse:
    """Orchestrates the quick report generation process."""
    
    usage_tracker = RunUsage()
    
    # 1. Planning & Search (Simplified)
    logger.info(f"Performing search for: '{user_query}'")
    search_task = [SearchTask(query=user_query, num_results=agency_config.num_search_results)]
    serper_cfg = SerperConfig.from_env()
    search_results_map = await execute_search_queries(search_task, serper_cfg, logger)
    search_results = search_results_map.get(user_query, [])
    usage_tracker.increment_serper_queries(1)
    
    logger.info(f"Found {len(search_results)} results. Calling reporter agent...")

    # 2. Writing the Report
    formatted_results = agents.format_search_results_for_prompt(search_results)
    user_prompt = agents.REPORTER_USER_MESSAGE_TEMPLATE.format(
        user_query=user_query,
        search_results_json=formatted_results
    )
    
    reporter_result = await agents_collection.reporter.run(user_prompt)
    usage_tracker.update_agent_usage("reporter", reporter_result.usage())
    
    report_data: schemas.Report = reporter_result.data
    
    logger.info("Report generation complete.")

    # 3. Final Response
    return schemas.QuickReportResponse(
        report=report_data,
        usage_statistics=usage_tracker.get_statistics()
    )
```

### Step 6: Define Callbacks (`callbacks.py`)

Create a simple callback handler to send status updates. Even a simple agency benefits from this for UI integration.

```python
# app/agencies/quick_report/callbacks.py
from __future__ import annotations
from typing import Optional, Callable, Coroutine, Any, Dict
import logging

logger = logging.getLogger(__name__)

class QuickReportWebSocketUpdateHandler:
    """Handles sending status updates for the Quick Report agency."""
    def __init__(self, websocket_callback: Optional[Callable[[Dict[str, Any]], Coroutine[Any, Any, None]]]):
        self._callback = websocket_callback

    async def _send_update(self, step: str, status: str, message: str, details: Optional[Dict] = None):
        if self._callback:
            payload = {"step": step, "status": status, "message": message, "details": details or {}}
            try:
                await self._callback(payload)
            except Exception as e:
                logger.error(f"Failed to send WebSocket update: {e}", exc_info=True)

    async def orchestration_start(self):
        await self._send_update("START", "IN_PROGRESS", "Starting quick report generation.")

    async def searching_start(self, query: str):
        await self._send_update("SEARCH", "IN_PROGRESS", f"Searching for: '{query}'...")

    async def writing_start(self):
        await self._send_update("WRITE", "IN_PROGRESS", "Writing report...")

    async def orchestration_complete(self, final_report: Dict):
        await self._send_update("COMPLETE", "SUCCESS", "Report finished.", {"report": final_report})

    async def orchestration_error(self, error: Exception):
        await self._send_update("ERROR", "FATAL", f"An error occurred: {error}")
```

### Step 7: Create the API Endpoint (`routes.py`)

Expose your orchestrator via a FastAPI WebSocket route.

```python
# app/agencies/quick_report/routes.py
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
import logging
from app.core.config import AppSettings
from app.core.dependencies import get_app_settings, get_llm_provider
from .orchestrator import run_quick_report_orchestration
from .agents import AgencyAgents
from .config import QuickReportConfig
from .callbacks import QuickReportWebSocketUpdateHandler

router = APIRouter()
logger = logging.getLogger(__name__)

@router.websocket("/ws/report")
async def research_websocket(websocket: WebSocket):
    await websocket.accept()
    
    # Instantiate core components
    settings: AppSettings = get_app_settings()
    llm_provider = get_llm_provider(settings)
    
    try:
        # Receive user query
        query_data = await websocket.receive_json()
        user_query = query_data.get("query")
        if not user_query:
            await websocket.close(code=1008, reason="Query not provided")
            return

        # Setup agency-specific components
        agency_config = QuickReportConfig()
        agents_collection = AgencyAgents.from_config(agency_config, llm_provider)

        # Setup callback handler
        async def send_update(payload: dict):
            await websocket.send_json(payload)
        
        update_handler = QuickReportWebSocketUpdateHandler(send_update)

        # Run the orchestration
        await update_handler.orchestration_start()
        
        # NOTE: This is a simplified example. In a real app, you'd integrate the
        # callback calls inside the orchestrator.
        await update_handler.searching_start(user_query)
        
        response = await run_quick_report_orchestration(
            user_query=user_query,
            agents_collection=agents_collection,
            agency_config=agency_config,
        )

        await update_handler.writing_start() # A bit out of order, for simplicity
        await update_handler.orchestration_complete(response.report.model_dump())

    except WebSocketDisconnect:
        logger.info("Client disconnected.")
    except Exception as e:
        logger.error(f"Error in Quick Report WebSocket: {e}", exc_info=True)
        # Inform the client of the error
        await websocket.send_json({"step": "ERROR", "status": "FATAL", "message": str(e)})
    finally:
        if not websocket.client_state.name == 'DISCONNECTED':
            await websocket.close()
```

### Step 8: Mount the Router in `app/main.py`

Finally, make your new agency's API endpoint available by adding it to the main FastAPI application.

```python
# app/main.py

# ... other imports
from app.agencies.deep_research import routes as deep_research_routes
from app.agencies.quick_report import routes as quick_report_routes # 1. Import your new routes

# ... app setup

# Include agency routers
app.include_router(deep_research_routes.router, prefix="/deep_research", tags=["Deep Research Agency"])
app.include_router(quick_report_routes.router, prefix="/quick_report", tags=["Quick Report Agency"]) # 2. Include your new router

# ... rest of the file
```

And that's it! You now have a new, fully functional agency. You can test it using a WebSocket client by connecting to `ws://localhost:8000/quick_report/ws/report` and sending a JSON payload like `{"query": "What are the benefits of using FastAPI?"}`.

This modular structure allows for rapid development and extension, enabling you to build a powerful, multi-faceted AI research system tailored to your specific needs. 